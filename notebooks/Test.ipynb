{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4653a12-e11c-465e-a973-4fe6587c9777",
   "metadata": {},
   "source": [
    "## Instantiate Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7d2483-0fa2-4023-abb9-41b8a85b9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, EntityRecognizer, Pattern, RecognizerResult\n",
    "from presidio_analyzer.recognizer_registry import RecognizerRegistry\n",
    "from presidio_analyzer.nlp_engine import NlpEngine, SpacyNlpEngine, NlpArtifacts\n",
    "from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n",
    "\n",
    "from presidio_anonymizer import AnonymizerEngine, DeanonymizeEngine, OperatorConfig\n",
    "from presidio_anonymizer.operators import Operator, OperatorType\n",
    "\n",
    "from typing import Dict, List\n",
    "import pprint\n",
    "\n",
    "class InstanceCounterAnonymizer(Operator):\n",
    "    \"\"\"\n",
    "    Anonymizer which replaces the entity value\n",
    "    with an instance counter per entity.\n",
    "    \"\"\"\n",
    "\n",
    "    REPLACING_FORMAT = \"<{entity_type}_{index}>\"\n",
    "\n",
    "    def operate(self, text: str, params: Dict = None) -> str:\n",
    "        \"\"\"Anonymize the input text.\"\"\"\n",
    "\n",
    "        entity_type: str = params[\"entity_type\"]\n",
    "\n",
    "        # entity_mapping is a dict of dicts containing mappings per entity type\n",
    "        entity_mapping: Dict[Dict:str] = params[\"entity_mapping\"]\n",
    "\n",
    "        entity_mapping_for_type = entity_mapping.get(entity_type)\n",
    "        if not entity_mapping_for_type:\n",
    "            new_text = self.REPLACING_FORMAT.format(\n",
    "                entity_type=entity_type, index=0\n",
    "            )\n",
    "            entity_mapping[entity_type] = {}\n",
    "\n",
    "        else:\n",
    "            if text in entity_mapping_for_type:\n",
    "                return entity_mapping_for_type[text]\n",
    "\n",
    "            previous_index = self._get_last_index(entity_mapping_for_type)\n",
    "            new_text = self.REPLACING_FORMAT.format(\n",
    "                entity_type=entity_type, index=previous_index + 1\n",
    "            )\n",
    "\n",
    "        entity_mapping[entity_type][text] = new_text\n",
    "        return new_text\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_last_index(entity_mapping_for_type: Dict) -> int:\n",
    "        \"\"\"Get the last index for a given entity type.\"\"\"\n",
    "\n",
    "        def get_index(value: str) -> int:\n",
    "            return int(value.split(\"_\")[-1][:-1])\n",
    "\n",
    "        indices = [get_index(v) for v in entity_mapping_for_type.values()]\n",
    "        return max(indices)\n",
    "\n",
    "    def validate(self, params: Dict = None) -> None:\n",
    "        \"\"\"Validate operator parameters.\"\"\"\n",
    "\n",
    "        if \"entity_mapping\" not in params:\n",
    "            raise ValueError(\"An input Dict called `entity_mapping` is required.\")\n",
    "        if \"entity_type\" not in params:\n",
    "            raise ValueError(\"An entity_type param is required.\")\n",
    "\n",
    "    def operator_name(self) -> str:\n",
    "        return \"entity_counter\"\n",
    "\n",
    "    def operator_type(self) -> OperatorType:\n",
    "        return OperatorType.Anonymize\n",
    "\n",
    "class InstanceCounterDeanonymizer(Operator):\n",
    "    \"\"\"\n",
    "    Deanonymizer which replaces the unique identifier \n",
    "    with the original text.\n",
    "    \"\"\"\n",
    "\n",
    "    def operate(self, text: str, params: Dict = None) -> str:\n",
    "        \"\"\"Anonymize the input text.\"\"\"\n",
    "\n",
    "        entity_type: str = params[\"entity_type\"]\n",
    "\n",
    "        # entity_mapping is a dict of dicts containing mappings per entity type\n",
    "        entity_mapping: Dict[Dict:str] = params[\"entity_mapping\"]\n",
    "\n",
    "        if entity_type not in entity_mapping:\n",
    "            raise ValueError(f\"Entity type {entity_type} not found in entity mapping!\")\n",
    "        if text not in entity_mapping[entity_type].values():\n",
    "            raise ValueError(f\"Text {text} not found in entity mapping for entity type {entity_type}!\")\n",
    "\n",
    "        return self._find_key_by_value(entity_mapping[entity_type], text)\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_key_by_value(entity_mapping, value):\n",
    "        for key, val in entity_mapping.items():\n",
    "            if val == value:\n",
    "                return key\n",
    "        return None\n",
    "    \n",
    "    def validate(self, params: Dict = None) -> None:\n",
    "        \"\"\"Validate operator parameters.\"\"\"\n",
    "\n",
    "        if \"entity_mapping\" not in params:\n",
    "            raise ValueError(\"An input Dict called `entity_mapping` is required.\")\n",
    "        if \"entity_type\" not in params:\n",
    "            raise ValueError(\"An entity_type param is required.\")\n",
    "\n",
    "    def operator_name(self) -> str:\n",
    "        return \"entity_counter_deanonymizer\"\n",
    "\n",
    "    def operator_type(self) -> OperatorType:\n",
    "        return OperatorType.Deanonymize\n",
    "\n",
    "# Define the recognizer with the defined pattern and context words \n",
    "# Creating 2 patterns - 1 for a perfect match, 1 for badly formed entries that require some context\n",
    "# May need to modify the weak one -> think about what cases we want captured by this one\n",
    "sortcode_pattern_full = Pattern(name=\"Sort Code Perfect\", regex=r\"\\b\\d{2}[-\\s]\\d{2}[-\\s]\\d{2}\\b\", score=1.0) # Standard pattern for sort code\n",
    "sortcode_pattern = Pattern(name=\"Sort Code (weak)\", regex=r\"\\b\\d{6}\\b\", score=0.001) # Sequence of 6 digits, need context to confirm if sort code\n",
    "\n",
    "# Score only increases when we added 'sort' to context words - it doesnt like strings with spaces\n",
    "sortcode_recognizer = PatternRecognizer(supported_entity=\"SORTCODE\", \n",
    "                                       patterns = [sortcode_pattern, sortcode_pattern_full],\n",
    "                                       context = [\"sortcode\", \"sort\"])\n",
    "registry = RecognizerRegistry()\n",
    "registry.load_predefined_recognizers()\n",
    "registry.add_recognizer(sortcode_recognizer)\n",
    "\n",
    "context_aware_enhancer = LemmaContextAwareEnhancer(context_similarity_factor=0.75, min_score_with_context_similarity=0.4)\n",
    "\n",
    "analyzer = AnalyzerEngine(registry=registry, context_aware_enhancer=context_aware_enhancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8bf229-1f8d-42a6-8130-192a752a1f67",
   "metadata": {},
   "source": [
    "## Test Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3213bf56-f5f5-4a54-ae77-12b77d8f28cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Let's assume I have a really long paragraph of text. Well, not super long, but still long enough that when I say sort code here, it will be a while until i actually provide it. I am going to fill some space between the actual value with some noise to see what happens if I provide the number after mentioning it initially. Here it is 345678\"\n",
    "\n",
    "analyzer_results = analyzer.analyze(text=text,language=\"en\")\n",
    "len(analyzer_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed11546-57a1-4021-b2df-0afcdf060396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[type: IN_PAN, start: 298, end: 308, score: 0.05,\n",
       " type: US_DRIVER_LICENSE, start: 334, end: 340, score: 0.01,\n",
       " type: SORTCODE, start: 334, end: 340, score: 0.001]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa33a2f-3ce6-470b-8d6d-659cbe973ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic entity types: DATE_TIME and US_DRIVER_LICENSE. Need to check these regex patterns.\n",
    "# Also, wtf is IN_PAN?\n",
    "# Write more test cases for sort code\n",
    "# I don't think we need that US_DRIVER_LICENSE recognizer, are there really any cases where a customer would need to provide that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca84ed-a977-47f3-b1e1-1b974cbba155",
   "metadata": {},
   "source": [
    "## Test Anonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c95355c-119e-45dc-8e95-6b3297bc5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Anonymizer engine and add the custom anonymizer\n",
    "anonymizer_engine = AnonymizerEngine()\n",
    "anonymizer_engine.add_anonymizer(InstanceCounterAnonymizer)\n",
    "\n",
    "# Create a mapping between entity types and counters\n",
    "entity_mapping = dict()\n",
    "\n",
    "# Anonymize the text\n",
    "anonymized_result = anonymizer_engine.anonymize(\n",
    "    text,\n",
    "    analyzer_results,\n",
    "    {\n",
    "        \"DEFAULT\": OperatorConfig(\n",
    "            \"entity_counter\", {\"entity_mapping\": entity_mapping}\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d51d328-2a90-4cfb-8b85-afed7f71a080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text: Let's assume I have a really long paragraph of text. Well, not super long, but still long enough that when I say sort code here, it will be a while until i actually provide it. I am going to fill some space between the actual value with some noise to see what happens if I provide the number after <IN_PAN_0> it initially. Here it is <US_DRIVER_LICENSE_0>\n",
       "items:\n",
       "[\n",
       "    {'start': 334, 'end': 355, 'entity_type': 'US_DRIVER_LICENSE', 'text': '<US_DRIVER_LICENSE_0>', 'operator': 'entity_counter'},\n",
       "    {'start': 298, 'end': 308, 'entity_type': 'IN_PAN', 'text': '<IN_PAN_0>', 'operator': 'entity_counter'}\n",
       "]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anonymized_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bc87a-7974-4939-8421-48ac6e046266",
   "metadata": {},
   "source": [
    "## Test Deanonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0e31c-0da7-40e4-87c6-b917ae9aa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "deanonymizer_engine = DeanonymizeEngine()\n",
    "deanonymizer_engine.add_deanonymizer(InstanceCounterDeanonymizer)\n",
    "\n",
    "deanonymized = deanonymizer_engine.deanonymize(\n",
    "    anonymized_result.text, \n",
    "    anonymized_result.items, \n",
    "    {\"DEFAULT\": OperatorConfig(\"entity_counter_deanonymizer\", \n",
    "                               params={\"entity_mapping\": entity_mapping})}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
